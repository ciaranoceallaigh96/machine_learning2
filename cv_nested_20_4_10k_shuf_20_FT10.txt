Script started on Fri 03 Dec 2021 00:36:03 GMT
bash: alias: NF} $1 | sort -nu | tail -n 1 : not found
(base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ source ~/venv/bin/activate
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ #python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_id s_first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

  File "cv_grid_all_ml.py", line 250
    model.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[1]-1,)))
                                                                                                                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ cv_grid_all_ml.pyvcv_grid_all_ml.pyicv_grid_all_ml.py cv_grid_all_ml.py
[?1049h[?1h=[1;52r[34l[34h[?25h[23m[24m[0m[H[J[?25l[52;1H"cv_grid_all_ml.py" 318L, 19186C[1;1H[34m#Warning : best model selected by NMAE and R2 might not be the same
#performs linear regression, linear regression, neural network, svm and random forest, LASSO, RIDGE, CNN
#source ~/venv/bin/activate #in python 3.5.2
#print a log to a .txt file!
#model = pickle.load(open('FILEPATH', 'rb')) 
#dependencies = {'coeff_determination':coeff_determination}
#model = tf.keras.models.load_model('FILEPATH', custom_objects=dependencies)
#

#import tensorflow
#import numpy as np; import scipy #need to do this before path insert
#import sys
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/')
#import dill as pickle
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv')
#from nested_cv import NestedCV
#with open('NCV_NN.pkl', 'rb') as f:
#     red = pickle.load(f)[0m

[36mprint[0m([31m"Please remember to set the right set size in the nested_cv code"[0m)
[35mimport[0m sys
sys.path.insert([31m1[0m, [31m'/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv'[0m)
num = sys.argv[[31m1[0m] [34m#script number for saving out[0m
phenfile = [36mstr[0m(sys.argv[[31m2[0m]) [34m#txt file with phenotypes[0m
data = [36mstr[0m(sys.argv[[31m3[0m]) [34m#needs to be same size as set_size[0m
snps = [36mstr[0m(sys.argv[[31m4[0m]) [34m#top or shuf[0m
phenotype = [36mstr[0m(sys.argv[[31m5[0m]) [34m#make a directory for the results[0m
set_size = [36mint[0m(sys.argv[[31m6[0m]) [34m#how many SNPs[0m
[35mfrom[0m nested_cv [35mimport[0m NestedCV
[35mimport[0m statistics
[35mimport[0m numpy [33mas[0m np
[35mimport[0m sklearn
[35mimport[0m seaborn [33mas[0m sns
[35mfrom[0m sklearn [35mimport[0m preprocessing
[35mfrom[0m sklearn.pipeline [35mimport[0m make_pipeline, Pipeline
[35mfrom[0m sklearn.preprocessing [35mimport[0m StandardScaler
[35mimport[0m datetime
[35mimport[0m time
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m matplotlib.pyplot [33mas[0m plt
[35mfrom[0m matplotlib [35mimport[0m style
[35mfrom[0m sklearn.svm [35mimport[0m LinearSVR
[35mfrom[0m sklearn.svm [35mimport[0m SVR
[35mfrom[0m sklearn.model_selection [35mimport[0m train_test_split
[35mfrom[0m sklearn.model_selection [35mimport[0m RandomizedSearchCV
[35mfrom[0m sklearn.linear_model [35mimport[0m LinearRegression, Lasso, Ridge
[34m#import pickle #use dill instead below[0m
[35mfrom[0m sklearn.ensemble [35mimport[0m RandomForestRegressor [34m#based in part on https://towardsdatascience.com/random-forest-in-python-24d0893d51c0[0m
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m os
[35mimport[0m pandas [33mas[0m pd [34m# data processing, CSV file I/O (e.g. pd.read_csv)[0m[52;194H1,1[11CTop[1;1H[34h[?25h[?25l[23m[24m[0m[H[J[1;1HNN_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name=[31m'NN'[0m)
nn_results([31m'NN'[0m, NN_NCV)

[36mprint[0m([31m"Performing a convulutional neural network"[0m)
[35mfrom[0m tensorboard.plugins.hparams [35mimport[0m api [33mas[0m hp
[35mimport[0m random
[35mfrom[0m tensorflow.keras.layers [35mimport[0m Dense, Conv1D, Flatten
cnn_param_grid = {[31m'model__epochs'[0m:[[31m200[0m],[31m'model__learning_rate'[0m : [[31m0.01[0m,[31m0.001[0m],[31m'model__HP_L1_REG'[0m : [[31m0.1[0m],[31m'model__HP_L2_REG'[0m : [[31m0.2[0m],[9;15H[31m'model__kernel_initializer'[0m : [[31m'glorot_uniform'[0m],[31m'model__activation'[0m : [[31m'tanh'[0m],[31m'model__HP_NUM_HIDDEN_LAYERS'[0m : [[31m3[0m],[10;15H[31m'model__units'[0m : [[31m200[0m], [31m'model__rate'[0m : [[36mfloat[0m([31m0[0m)],[31m'model__HP_OPTIMIZER'[0m : [[31m'SGD'[0m], [31m'model__batch_size'[0m: [[31m32[0m],[11;15H[31m'model__filters'[0m:[[31m1[0m,[31m2[0m],[31m'model__strides'[0m:[[31m1[0m,[31m2[0m],[31m'model__pool'[0m:[[31m1[0m,[31m2[0m],[31m'model__kernel'[0m:[[31m1[0m,[31m2[0m]}


cnn_param_grid = {[31m'epochs'[0m:[[31m200[0m, [31m100[0m],[31m'learning_rate'[0m : [[31m0.01[0m,[31m0.001[0m],[31m'HP_L1_REG'[0m : [[31m0.1[0m],[31m'HP_L2_REG'[0m : [[31m0.2[0m],[31m'kernel_initializer'[0m : [[31m'glorot_uniform'[0m],[31m'activation'[0m : [[31m'tanh'[0m],[31m'HP_NUM_HIDDEN_LAYERS'[0m : [[31m3[0m],[31m'units''[0m[15;1H : [[31m200[0m], [31m'rate'[0m : [[36mfloat[0m([31m0[0m)],[31m'HP_OPTIMIZER'[0m : [[31m'SGD'[0m], [31m'filters'[0m:[[31m1[0m,[31m2[0m],[31m'strides'[0m:[[31m1[0m,[31m2[0m],[31m'pool'[0m:[[31m1[0m,[31m2[0m],[31m'kernel'[0m:[[31m1[0m,[31m2[0m]}

METRIC_ACCURACY = [31m'coeff_determination'[0m
[34m#not sure if strides is relevant[0m
[36mprint[0m(x_train.shape)
[34m#x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1]) # You needs to reshape your input data according to Conv1D layer input format - (batch_size, steps, input_dim)
#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)
#x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)
#x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],1)
#x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1]) # You needs to reshape your input data according to Conv1D layer input format - (batch_size, steps, input_dim)[0m
[36mprint[0m(x_train.shape)

[33mdef[0m [36mconv_model[0m(HP_OPTIMIZER, HP_NUM_HIDDEN_LAYERS, units, activation, learning_rate, HP_L1_REG, HP_L2_REG, rate, kernel_initializer,strides,pool,filters,kernel):[28;9Hopt = HP_OPTIMIZER[29;9H[33mif[0m HP_NUM_HIDDEN_LAYERS == [31m1[0m :[30;17H[36mprint[0m([31m"HP_NUM_HIDDEN_LAYERS is equal to 1; this could cause building problems"[0m)[31;9Hchosen_opt = [36mgetattr[0m(tf.keras.optimizers,opt)[32;9Hreg = tf.keras.regularizers.l1_l2(l1=HP_L1_REG, l2=HP_L2_REG)[33;9Hmodel = Sequential() [34m# Only use dropout on fully-connected layers, and implement batch normalization between convolutions.[0m[34;9Hmodel.add(Conv1D(filters=filters, strides=strides, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,[31m1[0m), activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, kernel_size=kernel))[35;9Hmodel.add(tf.keras.layers.MaxPool1D(pool_size=pool, strides=strides))[36;9H[33mfor[0m i [33min[0m [36mrange[0m(HP_NUM_HIDDEN_LAYERS-[31m1[0m):[37;17Hmodel.add(Conv1D(filters=filters, strides=strides, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, kernel_size=kernel))[38;17Hmodel.add(tf.keras.layers.MaxPool1D(pool_size=pool, strides=strides))[39;9Hmodel.add(Flatten())[40;9Hmodel.add(Dense([31m1[0m, activation=[31m'linear'[0m))[41;9Hmodel.compile(loss=[31m'mean_absolute_error'[0m,metrics=[[31m'accuracy'[0m, [31m'mae'[0m, coeff_determination],optimizer=chosen_opt(learning_rate=learning_rate))[42;9H[36mprint[0m([31m"Summary "[0m, model.summary())[43;9H[33mreturn[0m model


cnn_model = KerasRegressor(build_fn = conv_model, epochs=[31m100[0m, verbose=[31m0[0m, batch_size=[31m32[0m)
CNN_NCV = NestedCV(model_name=[31m'CNN'[0m, name_list=name_list,model=cnn_model, params_grid=cnn_param_grid, outer_kfolds=[31m4[0m, inner_kfolds=[31m4[0m, n_jobs = [31m16[0m,cv_options={[31m'randomized_search'[0m:[36mTrue[0m, [31m'randomized_search_iter'[0m:[31m500[0m[48;1H, [31m'sqrt_of_score'[0m:[36mFalse[0m,[31m'recursive_feature_elimination'[0m:[36mFalse[0m, [31m'metric'[0m:sklearn.metrics.r2_score, [31m'metric_score_indicator_lower'[0m:[36mFalse[0m})
CNN_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name=[31m'CNN'[0m)
nn_results([31m'CNN'[0m, CNN_NCV)
[1m[34m~                                                                                                                                                                                                                  [0m[52;194H318,1[9CBot[50;1H[34h[?25h[?25l[52;196H7[49;1H[34h[?25h[?25l[52;196H6[47;1H[34h[?25h[?25l[52;196H5[46;1H[34h[?25h[?25l[52;196H4,1-8[45;8H[34h[?25h[?25l[52;196H3,1  [44;1H[34h[?25h[?25l[52;196H2[43;1H[34h[?25h[?25l[52;196H1[42;1H[34h[?25h[?25l[52;196H0[41;1H[34h[?25h[?25l[52;195H09[40;1H[34h[?25h[?25l[52;196H8[39;1H[34h[?25h[?25l[52;196H7[38;1H[34h[?25h[?25l[52;196H6[37;1H[34h[?25h[?25l[52;196H5[36;1H[34h[?25h[?25l[52;196H4[35;1H[34h[?25h[?25l[52;196H3[34;1H[34h[?25h[?25l[52;196H2[33;1H[34h[?25h[?25l[52;196H1[32;1H[34h[?25h[?25l[52;196H0[31;1H[34h[?25h[?25l[52;194H299[30;1H[34h[?25h[?25l[52;196H8[29;1H[34h[?25h[?25l[52;196H7[28;1H[34h[?25h[?25l[52;196H6[27;1H[34h[?25h[?25l[52;196H5,1-8[26;8H[34h[?25h[?25l[52;196H4,1  [25;1H[34h[?25h[?25l[52;196H3[24;1H[34h[?25h[?25l[52;196H2[23;1H[34h[?25h[?25l[52;196H1[22;1H[34h[?25h[?25l[52;196H0[21;1H[34h[?25h[?25l[52;195H89[20;1H[34h[?25h[?25l[52;196H8[19;1H[34h[?25h[?25l[52;196H7[18;1H[34h[?25h[?25l[52;196H6[17;1H[34h[?25h[?25l[52;196H5,0-1[16;1H[34h[?25h[?25l[52;196H4,1  [14;1H[34h[?25h[?25l[52;196H3,0-1[13;1H[34h[?25h[?25l[52;196H2[12;1H[34h[?25h[?25l[52;196H1,1-8[11;8H[34h[?25h[?25l[52;196H0[10;8H[34h[?25h[?25l[52;195H79[9;8H[34h[?25h[?25l[52;196H8,1  [8;1H[34h[?25h[?25l[52;196H7[7;1H[34h[?25h[?25l[52;196H6[6;1H[34h[?25h[?25l[52;196H5[5;1H[34h[?25h[?25l[52;196H4[4;1H[34h[?25h[?25l[52;196H3,0-1[3;1H[34h[?25h[?25l[52;196H2,1  [2;1H[34h[?25h[?25l[52;196H1[1;1H[34h[?25h[?25l[1;51r[1;1H[2L[1;52r[1;1HNN_NCV = NestedCV(model_name=[31m'nn_model'[0m, name_list = name_list, model=nn_model, params_grid=param_grid, outer_kfolds=[31m4[0m, inner_kfolds=[31m4[0m, n_jobs = [31m16[0m,cv_options={[31m'randomized_search'[0m:[36mTrue[0m, [31m'randomized_search_iter'[0m::[2;1H[31m50[0m, [31m'sqrt_of_score'[0m:[36mFalse[0m,[31m'recursive_feature_elimination'[0m:[36mFalse[0m, [31m'metric'[0m:sklearn.metrics.r2_score, [31m'metric_score_indicator_lower'[0m:[36mFalse[0m})[52;194H[K[52;194H270,1[9C99%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[52;194H[K[52;194H269,0-1[7C99%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[51;1H[1m[34m@                                                                                                                                                                                                                  [0m[52;194H[K[52;194H268,0-1[7C98%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1H[35mfrom[0m sklearn.model_selection [35mimport[0m cross_val_score[52;194H[K[52;194H267,1[9C98%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[52;194H[K[52;194H266,0-1[7C98%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1Hnn_model = KerasRegressor(build_fn = build_nn, epochs=[31m100[0m, verbose=[31m0[0m, batch_size=[31m32[0m)[52;194H[K[52;194H265,1[9C98%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1H[34m#pipeline_keras = Pipeline([('model', regressor_keras)])[0m[52;194H[K[52;194H264,1[9C97%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1H[34m#regressor_keras = KerasRegressor(build_fn = build_nn, epochs=10, verbose=1, batch_size=32)[0m[52;194H[K[52;194H263,1[9C97%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[52;194H[K[52;194H262,0-1[7C97%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[52;194H[K[52;194H261,0-1[7C96%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9H[33mreturn[0m model[52;194H[K[52;194H260,1-8[7C96%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9H[36mprint[0m(model.summary())[52;194H[K[52;194H259,1-8[7C95%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hmodel.compile(loss=[31m'mean_absolute_error'[0m,metrics=[[31m'accuracy'[0m, [31m'mae'[0m, coeff_determination],optimizer=chosen_opt(learning_rate=learning_rate))[52;194H[K[52;194H258,1-8[7C95%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hmodel.add(Dense([31m1[0m, activation=[31m'linear'[0m))[52;194H[K[52;194H257,1-8[7C95%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;25Hmodel.add(Dropout(rate=rate))[52;194H[K[52;194H256,1-8[7C94%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;17H[33mif[0m rate != [31m0[0m:[52;194H[K[52;194H255,1-8[7C94%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;17Hmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer))[52;194H[K[52;194H254,1-8[7C94%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9H[33mfor[0m i [33min[0m [36mrange[0m(HP_NUM_HIDDEN_LAYERS-[31m1[0m):[52;194H[K[52;194H253,1-8[7C93%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;17Hmodel.add(Dropout(rate=rate))[52;194H[K[52;194H252,1-8[7C93%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9H[33mif[0m rate != [31m0[0m:[52;194H[K[52;194H251,1-8[7C92%[1;8H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)))[52;194H[K[52;194H250,1[9C92%[1;1H[34h[?25h[?25l[52;198H2[1;2H[34h[?25h[?25l[52;198H1[1;1H[34h[?25h[?25l[52;196H1,1-8[2;8H[34h[?25h[?25l[52;1H[1m-- INSERT --[0m[52;194H[K[52;194H251,1[9C92%[2;1H[34h[?25h[?25l[52;196H2[3;1H[34h[?25h[?25l[52;196H3[4;1H[34h[?25h[?25l[52;196H4[5;1H[34h[?25h[?25l[52;196H5[6;1H[34h[?25h[?25l[52;196H6[7;1H[34h[?25h[?25l[52;196H7[8;1H[34h[?25h[?25l[52;198H2-9[8;9H[34h[?25h[?25l[52;198H1  [8;1H[34h[?25h[?25l[52;196H8[9;1H[34h[?25h[?25l[52;198H2-9[9;9H[34h[?25h[?25l[52;198H1  [9;1H[34h[?25h[?25l[52;196H9[10;1H[34h[?25h[?25l[52;198H2-9[10;9H[34h[?25h[?25l[52;198H1  [10;1H[34h[?25h[?25l[52;195H60[11;1H[34h[?25h[?25l[52;198H2-9[11;9H[34h[?25h[?25l[52;195H59[10;9H[34h[?25h[?25l[52;196H8[9;9H[34h[?25h[?25l[52;196H7[8;9H[34h[?25h[?25l[52;198H3-10[8;10H[34h[?25h[?25l[52;196H6,2-9 [7;9H[34h[?25h[?25l[52;196H5[6;9H[34h[?25h[?25l[52;198H3-17[6;17H[34h[?25h[?25l[52;196H6[7;17H[34h[?25h[?25l[52;198H4-25[7;25H[34h[?25h[?25l[52;198H3-17[7;17H[34h[?25h[?25l[52;198H2-9 [7;9H[34h[?25h[?25l[52;198H1  [7;1H[34h[?25h[?25l[52;196H5[6;1H[34h[?25h[?25l[52;198H2-9[6;9H[34h[?25h[?25l[52;198H3-17[6;17H[34h[?25h[?25l[52;196H4[5;17H[34h[?25h[?25l[52;198H2-9 [5;9H[34h[?25h[?25l[52;198H1  [5;1H[34h[?25h[?25l[52;196H3[4;1H[34h[?25h[?25l[52;198H2-9[4;9H[34h[?25h[?25l[52;196H2[3;9H[34h[?25h[?25l[52;198H3-17[3;17H[34h[?25h[?25l[52;198H2-9 [3;9H[34h[?25h[?25l[52;198H1  [3;1H[34h[?25h[?25l[52;196H1[2;1H[34h[?25h[?25l[52;198H2-9[2;9H[34h[?25h[?25l[52;198H1  [2;1H[34h[?25h[?25l[52;196H0[1;1H[34h[?25h[?25l[52;198H2[1;2H[34h[?25h[?25l[52;198H3[1;3H[34h[?25h[?25l[52;198H4[1;4H[34h[?25h[?25l[52;198H5[1;5H[34h[?25h[?25l[52;198H6[1;6H[34h[?25h[?25l[52;198H7[1;7H[34h[?25h[?25l[52;198H8[1;8H[34h[?25h[?25l[52;198H9[1;9H[34h[?25h[?25limodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)))[52;198H10[1;10H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;159H[K[52;198H9 [1;9H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;158H[K[52;198H8[1;8H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;157H[K[52;198H7[1;7H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;156H[K[52;198H6[1;6H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;155H[K[52;198H5[1;5H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;154H[K[52;198H4[1;4H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;153H[K[52;198H3[1;3H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;152H[K[52;198H2[1;2H[34h[?25h[?25lmodel.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)[1;151H[K[52;198H1[1;1H[34h[?25h[?25l        model.add(Dense(units=units, activation=activation, kernel_regularizer=reg, kernel_initializer=kernel_initializer, input_shape=(x_train.shape[[31m1[0m]-[31m1[0m,)))[52;198H2-9[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hmodel = Sequential()[52;194H[K[52;194H249,2-9[7C92%[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hreg = tf.keras.regularizers.l1_l2(l1=HP_L1_REG, l2=HP_L2_REG)[52;194H[K[52;194H248,2-9[7C91%[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hchosen_opt = [36mgetattr[0m(tf.keras.optimizers,opt)[52;194H[K[52;194H247,2-9[7C91%[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;9Hopt = HP_OPTIMIZER[52;194H[K[52;194H246,2-9[7C91%[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1H[33mdef[0m [36mbuild_nn[0m(HP_OPTIMIZER, HP_NUM_HIDDEN_LAYERS, units, activation, learning_rate, HP_L1_REG, HP_L2_REG, rate, kernel_initializer):[52;194H[K[52;194H245,9[9C90%[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[52;194H[K[52;194H244,1[9C90%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[52;194H[K[52;194H243,1[9C89%[1;1H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1H[34m#tf.config.experimental_run_functions_eagerly(True) #needed to avoid error # tensorflow.python.eager.core._SymbolicException[0m[52;194H[K[52;194H242,9[9C89%[1;9H[34h[?25h[?25l[1;51r[1;1H[L[1;52r[1;1Htf.config.threading.set_intra_op_parallelism_threads([31m64[0m)[52;194H[K[52;194H241,9[9C89%[1;9H[34h[?25h[?25l[52;196H2[2;9H[34h[?25h[?25l[52;196H3,1[3;1H[34h[?25h[?25l[52;196H4[4;1H[34h[?25h[?25l[52;196H5,9[5;9H[34h[?25h[?25l[52;196H6,2-9[6;9H[34h[?25h[?25l[52;196H7[7;9H[34h[?25h[?25l[52;196H8[8;9H[34h[?25h[?25l[52;196H9[9;9H[34h[?25h[?25l[52;198H1  [9;1H[34h[?25h[?25l[52;198H2-9[9;9H[34h[?25h[?25l[52;196H8[8;9H[34h[?25h[?25l[52;198H1  [8;1H[34h[?25h[?25l[52;198H2-9[8;9H[34h[?25h[52;1H[K[8;8H[?25l[52;194H248,1-8[7C89%[8;8H[34h[?25h[?25l[52;194H[K[52;1H:[34h[?25hx[?25l[34h[?25h[?25l"cv_grid_all_ml.py" 318L, 19179C written
[?1l>[34h[?25h[?1049l(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ vi cv_grid_all_ml.pypython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 00:37:00
Performing Neural Network
Traceback (most recent call last):
  File "cv_grid_all_ml.py", line 271, in <module>
    NN_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name='NN')
TypeError: fit() missing 2 required positional arguments: 'phenfile' and 'set_size'
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?1049h[?1h=[1;52r[34l[34h[?25h[23m[24m[0m[H[J[?25l[52;1H"cv_grid_all_ml.py" 318L, 19179C[1;1H[34m#Warning : best model selected by NMAE and R2 might not be the same
#performs linear regression, linear regression, neural network, svm and random forest, LASSO, RIDGE, CNN
#source ~/venv/bin/activate #in python 3.5.2
#print a log to a .txt file!
#model = pickle.load(open('FILEPATH', 'rb')) 
#dependencies = {'coeff_determination':coeff_determination}
#model = tf.keras.models.load_model('FILEPATH', custom_objects=dependencies)
#

#import tensorflow
#import numpy as np; import scipy #need to do this before path insert
#import sys
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/')
#import dill as pickle
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv')
#from nested_cv import NestedCV
#with open('NCV_NN.pkl', 'rb') as f:
#     red = pickle.load(f)[0m

[36mprint[0m([31m"Please remember to set the right set size in the nested_cv code"[0m)
[35mimport[0m sys
sys.path.insert([31m1[0m, [31m'/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv'[0m)
num = sys.argv[[31m1[0m] [34m#script number for saving out[0m
phenfile = [36mstr[0m(sys.argv[[31m2[0m]) [34m#txt file with phenotypes[0m
data = [36mstr[0m(sys.argv[[31m3[0m]) [34m#needs to be same size as set_size[0m
snps = [36mstr[0m(sys.argv[[31m4[0m]) [34m#top or shuf[0m
phenotype = [36mstr[0m(sys.argv[[31m5[0m]) [34m#make a directory for the results[0m
set_size = [36mint[0m(sys.argv[[31m6[0m]) [34m#how many SNPs[0m
[35mfrom[0m nested_cv [35mimport[0m NestedCV
[35mimport[0m statistics
[35mimport[0m numpy [33mas[0m np
[35mimport[0m sklearn
[35mimport[0m seaborn [33mas[0m sns
[35mfrom[0m sklearn [35mimport[0m preprocessing
[35mfrom[0m sklearn.pipeline [35mimport[0m make_pipeline, Pipeline
[35mfrom[0m sklearn.preprocessing [35mimport[0m StandardScaler
[35mimport[0m datetime
[35mimport[0m time
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m matplotlib.pyplot [33mas[0m plt
[35mfrom[0m matplotlib [35mimport[0m style
[35mfrom[0m sklearn.svm [35mimport[0m LinearSVR
[35mfrom[0m sklearn.svm [35mimport[0m SVR
[35mfrom[0m sklearn.model_selection [35mimport[0m train_test_split
[35mfrom[0m sklearn.model_selection [35mimport[0m RandomizedSearchCV
[35mfrom[0m sklearn.linear_model [35mimport[0m LinearRegression, Lasso, Ridge
[34m#import pickle #use dill instead below[0m
[35mfrom[0m sklearn.ensemble [35mimport[0m RandomForestRegressor [34m#based in part on https://towardsdatascience.com/random-forest-in-python-24d0893d51c0[0m
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m os
[35mimport[0m pandas [33mas[0m pd [34m# data processing, CSV file I/O (e.g. pd.read_csv)[0m[52;194H1,1[11CTop[1;1H[34h[?25h[?25l[52;194H2[2;1H[34h[?25h[?25l[52;194H3[3;1H[34h[?25h[?25l[52;194H4[4;1H[34h[?25h[?25l[52;194H5[5;1H[34h[?25h[?25l[52;194H6[6;1H[34h[?25h[?25l[52;194H7[7;1H[34h[?25h[?25l[52;194H8[8;1H[34h[?25h[?25l[52;194H9,0-1[9;1H[34h[?25h[?25l[52;194H10,1 [10;1H[34h[?25h[?25l[52;195H1[11;1H[34h[?25h[?25l[52;195H2[12;1H[34h[?25h[?25l[52;195H3[13;1H[34h[?25h[?25l[52;195H4[14;1H[34h[?25h[?25l[52;195H5[15;1H[34h[?25h[?25l[52;195H6[16;1H[34h[?25h[?25l[52;195H7[17;1H[34h[?25h[?25l[52;195H8[18;1H[34h[?25h[?25l[52;195H9,0-1[19;1H[34h[?25h[?25l[52;194H20,1  [20;1H[34h[?25h[?25l[52;195H1[21;1H[34h[?25h[?25l[52;195H2[22;1H[34h[?25h[?25l[52;195H3[23;1H[34h[?25h[?25l[52;195H4[24;1H[34h[?25h[?25l[52;195H5[25;1H[34h[?25h[?25l[52;195H6[26;1H[34h[?25h[?25l[52;195H7[27;1H[34h[?25h[?25l[52;195H8[28;1H[34h[?25h[?25l[52;195H9[29;1H[34h[?25h[?25l[52;194H30[30;1H[34h[?25h[?25l[52;195H1[31;1H[34h[?25h[?25l[52;195H2[32;1H[34h[?25h[?25l[52;195H3[33;1H[34h[?25h[?25l[52;195H4[34;1H[34h[?25h[?25l[52;195H5[35;1H[34h[?25h[?25l[52;195H6[36;1H[34h[?25h[?25l[52;195H7[37;1H[34h[?25h[?25l[52;195H8[38;1H[34h[?25h[?25l[52;195H9[39;1H[34h[?25h[?25l[52;194H40[40;1H[34h[?25h[?25l[52;195H1[41;1H[34h[?25h[?25l[52;195H2[42;1H[34h[?25h[?25l[52;195H3[43;1H[34h[?25h[?25l[52;195H4[44;1H[34h[?25h[?25l[52;195H5[45;1H[34h[?25h[?25l[52;195H6[46;1H[34h[?25h[?25l[52;195H7[47;1H[34h[?25h[?25l[52;195H8[48;1H[34h[?25h[?25l[52;195H9[49;1H[34h[?25h[?25l[52;194H50[50;1H[34h[?25h[?25l[52;195H1[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m sklearn.metrics [35mimport[0m make_scorer[52;1H[K[52;194H52,1[11C0%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mimport[0m tensorflow [33mas[0m tf[52;194H[K[52;194H53,1[11C0%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.python.keras [35mimport[0m backend [33mas[0m K[52;194H[K[52;194H54,1[11C1%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.layers [35mimport[0m Dense, Dropout, Flatten [34m#.core[0m[52;194H[K[52;194H55,1[11C1%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.optimizers [35mimport[0m SGD[52;194H[K[52;194H56,1[11C1%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.layers [35mimport[0m Dropout[52;194H[K[52;194H57,1[11C2%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m sklearn.externals [35mimport[0m joblib[52;194H[K[52;194H58,1[11C2%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.models [35mimport[0m Sequential[52;194H[K[52;194H59,1[11C2%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.layers [35mimport[0m Dense[52;194H[K[52;194H60,1[11C3%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.wrappers.scikit_learn [35mimport[0m KerasRegressor [34m# or Classifier[0m[52;194H[K[52;194H61,1[11C3%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m sklearn.model_selection [35mimport[0m KFold[52;194H[K[52;194H62,1[11C4%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.optimizers [35mimport[0m SGD[52;194H[K[52;194H63,1[11C4%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorflow.keras.layers [35mimport[0m Dropout[52;194H[K[52;194H64,1[11C4%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mimport[0m random[52;194H[K[52;194H65,1[11C5%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorboard.plugins.hparams [35mimport[0m api [33mas[0m hp[52;194H[K[52;194H66,1[11C5%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#https://github.com/WillKoehrsen/Machine-Learning-Projects/blob/master/random_forest_explained/Improving%20Random%20Forest%20Part%202.ipynb[0m[52;194H[K[52;194H67,1[11C5%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mfrom[0m tensorboard.plugins.hparams [35mimport[0m api [33mas[0m hp[52;194H[K[52;194H68,1[11C6%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mimport[0m random[52;194H[K[52;194H69,1[11C6%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H70,0-1[9C7%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#if snps == 'shuf' :[0m[52;194H[K[52;194H71,1[11C7%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#       print("Shuf nestedCV in usage")[0m[52;194H[K[52;194H72,1[11C7%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#       from nested_cv_shuf import NestedCV[0m[52;194H[K[52;194H73,1[11C8%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#elif snps == 'top':[0m[52;194H[K[52;194H74,1[11C8%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#       from nested_cv import NestedCV[0m[52;194H[K[52;194H75,1[11C8%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#else:[0m[52;194H[K[52;194H76,1[11C9%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#       print("snnps must be top or shuf")[0m[52;194H[K[52;194H77,1[11C9%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H78,1-8[8C10%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H79,0-1[8C10%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hsys.path.insert([31m1[0m, [31m'/external_storage/ciaran/Library/Python/3.7/python/site-packages/'[0m)[52;194H[K[52;194H80,1[10C10%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[35mimport[0m dill [33mas[0m pickle[52;194H[K[52;194H81,1[10C11%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mfor[0m i [33min[0m [36mrange[0m([31m1[0m,[36mlen[0m(sys.argv)):[52;194H[K[52;194H82,1[10C11%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m(sys.argv[i])[52;194H[K[52;194H83,1-8[8C11%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H84,0-1[8C12%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mif[0m [33mnot[0m os.path.exists([31m'/external_storage/ciaran/arabadopsis/'[0m + phenotype+ [31m'/'[0m + snps):[52;194H[K[52;194H85,1[10C12%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;5Hos.makedirs([31m'/external_storage/ciaran/arabadopsis/'[0m + phenotype+ [31m'/'[0m + snps)[52;194H[K[52;194H86,1[10C13%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H87,0-1[8C13%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hos.chdir([31m'/external_storage/ciaran/arabadopsis/'[0m + phenotype+ [31m'/'[0m + snps)[52;194H[K[52;194H88,1[10C13%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hdate_object = datetime.datetime.now().replace(second=[31m0[0m,microsecond=[31m0[0m)[52;194H[K[52;194H89,1[10C14%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[36mprint[0m(date_object)[52;194H[K[52;194H90,1[10C14%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H91,0-1[8C14%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mdef[0m [36mcoeff_determination[0m(y_true, y_pred):[52;194H[K[52;194H92,1[10C15%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9HSS_res = K.sum(K.square( y_true-y_pred ))[52;194H[K[52;194H93,1[10C15%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9HSS_tot = K.sum(K.square( y_true - K.mean(y_true)))[52;194H[K[52;194H94,1[10C16%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mreturn[0m ([31m1[0m-SS_res/SS_tot)[52;194H[K[52;194H95,1[10C16%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H96,0-1[8C16%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H97,0-1[8C17%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mdef[0m [36mload_data[0m(data):[52;194H[K[52;194H98,1[10C17%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hdataset = np.loadtxt(data, skiprows=[31m1[0m)[52;194H[K[52;194H99,1[10C17%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hx = dataset[: , [31m6[0m:set_size]/[31m2[0m[52;194H[K[52;194H100,1[9C18%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hy = dataset[: , [31m5[0m ][52;194H[K[52;194H101,1[9C18%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hy = y.reshape(-[31m1[0m,[31m1[0m)[52;194H[K[52;194H102,1[9C19%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[34m#print("Performing split of raw data....")[0m[52;194H[K[52;194H103,1[9C19%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[34m#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=42)[0m[52;194H[K[52;194H104,1[9C19%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mreturn[0m x, y [34m#x_train, y_train, x_test, y_test[0m[52;194H[K[52;194H105,1[9C20%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H106,0-1[7C20%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H107,0-1[7C20%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H108,0-1[7C21%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mwith[0m [36mopen[0m(([31m'validation_results_'[0m+ [36mstr[0m(snps) +[36mstr[0m(num) + phenotype + [36mstr[0m([31m"{:%Y_%m_%d}"[0m.format(datetime.datetime.now())) + [31m'.vallog'[0m ), [31m'a'[0m) [33mas[0m f:[52;194H[K[52;194H109,1[9C21%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Horiginal_stdout = sys.stdout [34m# Save a reference to the original standard output[0m[52;194H[K[52;194H110,1[9C22%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hsys.stdout = f [34m# Change the standard output to the file we created.[0m[52;194H[K[52;194H111,1[9C22%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m(datetime.datetime.now())[52;194H[K[52;194H112,1[9C22%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hsys.stdout = original_stdout[52;194H[K[52;194H113,1[9C23%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H114,0-1[7C23%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mdef[0m [36mbaseline[0m(x, y):[52;194H[K[52;194H115,1[9C23%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hmodel = LinearRegression()[52;194H[K[52;194H116,1[9C24%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hmodel.fit(x, y)[52;194H[K[52;194H117,1[9C24%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mreturn[0m model[52;194H[K[52;194H118,1[9C25%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H119,0-1[7C25%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H120,0-1[7C25%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mdef[0m [36mavg_cv_result[0m(measure,cv_result):[52;194H[K[52;194H121,1[9C26%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hmy_var_name = [k [33mfor[0m k,v [33min[0m [36mlocals[0m().items() [33mif[0m v == measure][[31m0[0m] [34m#just to print out the name[0m[52;194H[K[52;194H122,1-8[7C26%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m(my_var_name)[52;194H[K[52;194H123,1-8[7C26%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hn_combos = [36mlen[0m(cv_result.cv_results_[[31m'split0_test_neg_mean_absolute_error'[0m])[52;194H[K[52;194H124,1-8[7C27%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hnamed_dict = {} [34m#dictonary will have a list of results PER grid combination across all CV results and this will return the average result. [0m[52;194H[K[52;194H125,1-8[7C27%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Havg_list = [][52;194H[K[52;194H126,1-8[7C28%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mfor[0m combo [33min[0m [36mrange[0m([31m0[0m, n_combos):[52;194H[K[52;194H127,1-8[7C28%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;17Hnamed_dict[[36mstr[0m(combo)] = [][52;194H[K[52;194H128,1-8[7C28%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;17H[33mfor[0m split [33min[0m measure:[52;194H[K[52;194H129,1-8[7C29%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;25Hnamed_dict[[36mstr[0m(combo)].append(cv_result.cv_results_[split][combo])[52;194H[K[52;194H130,1-8[7C29%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;17Havg_list.append(statistics.mean(named_dict[[36mstr[0m(combo)]))[52;194H[K[52;194H131,1-8[7C29%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;17H[36mprint[0m(combo, statistics.mean(named_dict[[36mstr[0m(combo)]))[52;194H[K[52;194H132,1-8[7C30%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H133,0-1[7C30%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m'Max'[0m, np.nanmax(avg_list), np.where(avg_list == np.nanmax(avg_list)))[52;194H[K[52;194H134,1-8[7C31%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m'Min'[0m, np.nanmin(avg_list), np.where(avg_list == np.nanmin(avg_list)))[52;194H[K[52;194H135,1-8[7C31%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mreturn[0m avg_list[52;194H[K[52;194H136,1-8[7C31%[51;8H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H137,0-1[7C32%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hx_train, y_train = load_data(data)[52;194H[K[52;194H138,1[9C32%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hname_list = np.loadtxt(data, skiprows=[31m1[0m, usecols=([31m0[0m,), dtype=[31m'str'[0m)[52;194H[K[52;194H139,1[9C32%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H140,0-1[7C33%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hscaler = preprocessing.StandardScaler().fit(y_train)[52;194H[K[52;194H141,1[9C33%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#pickle.dump(scaler, open('scaler.pkl', 'wb'))[0m[52;194H[K[52;194H142,1[9C34%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#scaler = pickle.load(open('scaler.pkl', 'rb'))[0m[52;194H[K[52;194H143,1[9C34%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H144,0-1[7C34%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hy_train = scaler.transform(y_train)[52;194H[K[52;194H145,1[9C35%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H146,0-1[7C35%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hn_snps = x_train.shape[[31m1[0m][52;194H[K[52;194H147,1[9C35%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1Hmy_cv = sklearn.model_selection.KFold(n_splits=[31m10[0m, shuffle=[36mTrue[0m, random_state=[31m42[0m)[52;194H[K[52;194H148,1[9C36%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[34m#################################################SVM####SVM#####SVM####################################################################[0m[52;194H[K[52;194H149,1[9C36%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mdef[0m [36mncv_results[0m(analysis, ncv_object):[52;194H[K[52;194H150,1[9C37%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m"Best Params of %s is %s "[0m % (analysis, ncv_object.best_params))[52;194H[K[52;194H151,1[9C37%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m"Outer scores of %s is %s and mean is %s"[0m % (analysis, ncv_object.outer_scores, np.mean(ncv_object.outer_scores)))[52;194H[K[52;194H152,1[9C37%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m"Variance of %s is %s "[0m % (analysis, ncv_object.variance))[52;194H[K[52;194H153,1[9C38%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mwith[0m [36mopen[0m([31m'NCV_'[0m + [36mstr[0m(analysis) + [31m'_'[0m +  [36mstr[0m(snps) + [31m'_'[0m + [36mstr[0m(phenotype) + [31m'_'[0m + [36mstr[0m(num) + [31m'.pkl'[0m, [31m'wb'[0m) [33mas[0m ncvfile: [34m#with open("fname.pkl", 'rb') as ncvfile:[0m[52;194H[K[52;194H154,1[9C38%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;17Hpickle.dump(ncv_object, ncvfile) [34m#ncv_object = pickle.load(ncvfile)[0m[52;194H[K[52;194H155,1[9C38%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H156,0-1[7C39%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[33mdef[0m [36mnn_results[0m(analysis, ncv_object):[52;194H[K[52;194H157,1[9C39%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m"Best Params of %s is %s "[0m % (analysis, ncv_object.best_params))[52;194H[K[52;194H158,1[9C40%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m"Outer scores of %s is %s and mean is %s"[0m % (analysis, ncv_object.outer_scores, np.mean(ncv_object.outer_scores)))[52;194H[K[52;194H159,1[9C40%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[36mprint[0m([31m"Variance of %s is %s "[0m % (analysis, ncv_object.variance))[52;194H[K[52;194H160,1[9C40%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hnn_list = [ncv_object.best_inner_params_list, ncv_object.best_inner_score_list, ncv_object.best_params, ncv_object.metric, ncv_object.outer_scores, ncv_object.variance][52;194H[K[52;194H161,1[9C41%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9H[33mwith[0m [36mopen[0m([31m'NCV_'[0m + [36mstr[0m(analysis) + [31m'_'[0m +  [36mstr[0m(snps) + [31m'_'[0m + [36mstr[0m(phenotype) + [31m'_'[0m + [36mstr[0m(num) + [31m'.pkl'[0m, [31m'wb'[0m) [33mas[0m ncvfile:[52;194H[K[52;194H162,1[9C41%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;17Hpickle.dump(nn_list, ncvfile) [34m#ncv_object = pickle.load(ncvfile)[0m[52;194H[K[52;194H163,1[9C41%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;9Hncv_object.model.model.save([31m"model_"[0m + [36mstr[0m(analysis) + [31m'_'[0m +  [36mstr[0m(snps) + [31m'_'[0m + [36mstr[0m(phenotype) + [31m'_'[0m + [36mstr[0m(num) + [31m".h5"[0m)[52;194H[K[52;194H164,1[9C42%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H165,0-1[7C42%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31m'''[0m[52;194H[K[52;194H166,1[9C43%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint("Performing SVM")[0m[52;194H[K[52;194H167,1[9C43%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mc_param = [1,2][0m[52;194H[K[52;194H168,1[9C43%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mgamma_param = [float(x) for x in np.linspace(0.1, 1, 4)][0m[52;194H[K[52;194H169,1[9C44%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H170,0-1[7C44%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H171,0-1[7C44%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mepsilon_param = [float(x) for x in np.linspace(0.1, 1, 4)][0m[52;194H[K[52;194H172,1[9C45%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mloss_param = ['epsilon_insensitive', 'squared_epsilon_insensitive'][0m[52;194H[K[52;194H173,1[9C45%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mkernel_param = ['poly'][0m[52;194H[K[52;194H174,1[9C46%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mdegree = [1,2,3][0m[52;194H[K[52;194H175,1[9C46%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31msvm_random_grid = {'gamma':gamma_param, 'C':c_param,'kernel':kernel_param, "degree":degree}[0m[52;194H[K[52;194H176,1[9C46%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint(svm_random_grid)[0m[52;194H[K[52;194H177,1[9C47%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31msvm_random_grid2 = {'C' : c_param, 'loss':loss_param}[0m[52;194H[K[52;194H178,1[9C47%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint(svm_random_grid2)[0m[52;194H[K[52;194H179,1[9C47%[51;1H[34h[?25h[?25l[1;51r[1;1H[2M[1;52r[50;1H[31mSVM_NCV = NestedCV(model_name='LinearSVR', name_list = name_list, model=LinearSVR(), params_grid=svm_random_grid2, outer_kfolds=4, inner_kfolds=4, n_jobs = 8,cv_options={'randomized_search':True, 'randomized_seaa[51;1Hrch_iter':50, 'sqrt_of_score':False,'recursive_feature_elimination':False, 'metric':sklearn.metrics.r2_score, 'metric_score_indicator_lower':False})[0m[52;194H[K[52;194H180,1[9C48%[50;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mSVM_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name='SVM')[0m[52;194H[K[52;194H181,1[9C48%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H182,0-1[7C49%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H183,0-1[7C49%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mncv_results('SVM', SVM_NCV)     [0m[52;194H[K[52;194H184,1[9C50%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint("Performing RBG")[0m[52;194H[K[52;194H185,1[9C50%[51;1H[34h[?25h[?25l[1;51r[1;1H[2M[1;52r[50;1H[31mRBG_NCV = NestedCV(model_name='RBG', name_list=name_list, model=SVR(), params_grid=svm_random_grid, outer_kfolds=4, inner_kfolds=4, n_jobs = 8,cv_options={'randomized_search':True, 'randomized_search_iter':50, ''[51;1Hsqrt_of_score':False,'recursive_feature_elimination':False, 'metric':sklearn.metrics.r2_score, 'metric_score_indicator_lower':False})[0m[52;194H[K[52;194H186,1[9C50%[50;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mRBG_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name='RBG')[0m[52;194H[K[52;194H187,1[9C51%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mncv_results('RBG', RBG_NCV)[0m[52;194H[K[52;194H188,1[9C51%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[52;194H[K[52;194H189,0-1[7C52%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint("Performing LASSO")[0m[52;194H[K[52;194H190,1[9C52%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31malpha = [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 100][0m[52;194H[K[52;194H191,1[9C52%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31malpha_dict = {'alpha':alpha}[0m[52;194H[K[52;194H192,1[9C53%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint(alpha_dict)[0m[52;194H[K[52;194H193,1[9C53%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31malpha_name_dict = {'alpha':"Alpha"}[0m[52;194H[K[52;194H194,1[9C53%[51;1H[34h[?25h[?25l[1;51r[1;1H[2M[1;52r[50;1H[31mLASS_NCV = NestedCV(model_name='LASS', name_list=name_list, model=Lasso(), params_grid=alpha_dict, outer_kfolds=4, inner_kfolds=4, n_jobs = 8,cv_options={'randomized_search':True, 'randomized_search_iter':50, 'ss[51;1Hqrt_of_score':False,'recursive_feature_elimination':False, 'metric':sklearn.metrics.r2_score, 'metric_score_indicator_lower':False})[0m[52;194H[K[52;194H195,1[9C54%[50;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mLASS_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name='LASS')[0m[52;194H[K[52;194H196,1[9C54%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mncv_results('LASS', LASS_NCV)[0m[52;194H[K[52;194H197,1[9C55%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint("Performing Ridge")[0m[52;194H[K[52;194H198,1[9C55%[51;1H[34h[?25h[?25l[1;51r[1;1H[2M[1;52r[50;1H[31mRIDGE_NCV = NestedCV(model_name='RIDGE', name_list=name_list, model=Ridge(), params_grid=alpha_dict, outer_kfolds=4, inner_kfolds=4, n_jobs = 8,cv_options={'randomized_search':True, 'randomized_search_iter':50,  [51;1H'sqrt_of_score':False,'recursive_feature_elimination':False, 'metric':sklearn.metrics.r2_score, 'metric_score_indicator_lower':False})[0m[52;194H[K[52;194H199,1[9C56%[50;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mRIDGE_NCV.fit(x_train, y_train.ravel(), name_list=name_list, model_name='RIDGE')[0m[52;194H[K[52;194H200,1[9C56%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mncv_results('RIDGE', RIDGE_NCV)[0m[52;194H[K[52;194H201,1[9C56%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mprint("Performing Random Forests")[0m[52;194H[K[52;194H202,1[9C57%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mn_estimators = [int(x) for x in np.linspace(start = 2000, stop = 9000, num = 50)] # Number of features to consider at every split[0m[52;194H[K[52;194H203,1[9C57%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mmax_features = ['auto', 'sqrt', 'log2'] # Maximum number of levels in tree[0m[52;194H[K[52;194H204,1[9C57%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mmax_depth = [int(x) for x in np.linspace(1, 100, num = 20)][0m[52;194H[K[52;194H205,1[9C58%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mmax_depth.append(None) # Minimum number of samples required to split a node[0m[52;194H[K[52;194H206,1[9C58%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31m#min_samples_split = [int(x) for x in np.linspace(2, 2000, num = 100)]; min_samples_split.extend((5,10,20))[0m[52;194H[K[52;194H207,1[9C59%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mmin_samples_split = [2,3,4, 10, 100] # Minimum number of samples required at each leaf node[0m[52;194H[K[52;194H208,1[9C59%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31m#min_samples_leaf = [int(x) for x in np.linspace(1, 2000, num = 200)] ; min_samples_leaf.extend((2,4,8,16, 32, 64)) # Method of selecting samples for training each tree[0m[52;194H[K[52;194H209,1[9C59%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mmin_samples_leaf = [1,2,3, 10, 100][0m[52;194H[K[52;194H210,1[9C60%[51;1H[34h[?25h[?25l[1;51r[51;1H
[1;52r[51;1H[31mbootstrap = [True, False][0m[52;194H[K[52;194H211,1[9C60%[51;1H[34h[?25h[?25l[52;194H[K[52;1H:[34h[?25hq[?25l[34h[?25h![?25l[34h[?25h[?25l[52;1H[K[52;1H[?1l>[34h[?25h[?1049l(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ hgre[K[K[K[Kgrep 'name_list=name_list, model_name' cv_grid_all_ml.py
SVM_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='SVM')
RBG_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='RBG')
LASS_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='LASS')
RIDGE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='RIDGE')
RF_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='RF')
BASELINE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='baseline')
NN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='NN')
CNN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, model_name[m[K='CNN')
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ sed -i 's/cv_grid_all_ml.py[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kname_list=name_list, model_name/name_list=name_list, model_name/g' cv_grid_all_ml.py[1@p[1@h[1@e[1@n[1@f[1@i[1@l[1@e[1@=[1@p[1@h[1@e[1@n[1@f[1@i[1@l[1@e[1@,[1@ [1@s[1@e[1@t[1@_[1@s[1@i[1@z[1@e[1@=[1@s[1@e[1@t[1@_[1@s[1@i[1@z[1@e[1@,[1@ 
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g' cv_grid_all_ml.py[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ grep 'name_list=name_list, model_name' cv_grid_all_ml.py[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1@p
SVM_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='SVM')
RBG_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='RBG')
LASS_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='LASS')
RIDGE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='RIDGE')
RF_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='RF')
BASELINE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='baseline')
NN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='NN')
CNN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='CNN')
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ grep 'name_list=name_list, p' cv_grid_all_ml.py[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[36Pvi[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?1049h[?1h=[1;52r[34l[34h[?25h[23m[24m[0m[H[J[?25l[52;1H"cv_grid_all_ml.py" 318L, 19483C[1;1H[34m#Warning : best model selected by NMAE and R2 might not be the same
#performs linear regression, linear regression, neural network, svm and random forest, LASSO, RIDGE, CNN
#source ~/venv/bin/activate #in python 3.5.2
#print a log to a .txt file!
#model = pickle.load(open('FILEPATH', 'rb')) 
#dependencies = {'coeff_determination':coeff_determination}
#model = tf.keras.models.load_model('FILEPATH', custom_objects=dependencies)
#

#import tensorflow
#import numpy as np; import scipy #need to do this before path insert
#import sys
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/')
#import dill as pickle
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv')
#from nested_cv import NestedCV
#with open('NCV_NN.pkl', 'rb') as f:
#     red = pickle.load(f)[0m

[36mprint[0m([31m"Please remember to set the right set size in the nested_cv code"[0m)
[35mimport[0m sys
sys.path.insert([31m1[0m, [31m'/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv'[0m)
num = sys.argv[[31m1[0m] [34m#script number for saving out[0m
phenfile = [36mstr[0m(sys.argv[[31m2[0m]) [34m#txt file with phenotypes[0m
data = [36mstr[0m(sys.argv[[31m3[0m]) [34m#needs to be same size as set_size[0m
snps = [36mstr[0m(sys.argv[[31m4[0m]) [34m#top or shuf[0m
phenotype = [36mstr[0m(sys.argv[[31m5[0m]) [34m#make a directory for the results[0m
set_size = [36mint[0m(sys.argv[[31m6[0m]) [34m#how many SNPs[0m
[35mfrom[0m nested_cv [35mimport[0m NestedCV
[35mimport[0m statistics
[35mimport[0m numpy [33mas[0m np
[35mimport[0m sklearn
[35mimport[0m seaborn [33mas[0m sns
[35mfrom[0m sklearn [35mimport[0m preprocessing
[35mfrom[0m sklearn.pipeline [35mimport[0m make_pipeline, Pipeline
[35mfrom[0m sklearn.preprocessing [35mimport[0m StandardScaler
[35mimport[0m datetime
[35mimport[0m time
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m matplotlib.pyplot [33mas[0m plt
[35mfrom[0m matplotlib [35mimport[0m style
[35mfrom[0m sklearn.svm [35mimport[0m LinearSVR
[35mfrom[0m sklearn.svm [35mimport[0m SVR
[35mfrom[0m sklearn.model_selection [35mimport[0m train_test_split
[35mfrom[0m sklearn.model_selection [35mimport[0m RandomizedSearchCV
[35mfrom[0m sklearn.linear_model [35mimport[0m LinearRegression, Lasso, Ridge
[34m#import pickle #use dill instead below[0m
[35mfrom[0m sklearn.ensemble [35mimport[0m RandomForestRegressor [34m#based in part on https://towardsdatascience.com/random-forest-in-python-24d0893d51c0[0m
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m os
[35mimport[0m pandas [33mas[0m pd [34m# data processing, CSV file I/O (e.g. pd.read_csv)[0m[52;194H1,1[11CTop[1;1H[34h[?25h[?25l[52;194H2[2;1H[34h[?25h[?25l[52;194H3[3;1H[34h[?25h[?25l[52;194H4[4;1H[34h[?25h[?25l[52;194H5[5;1H[34h[?25h[?25l[52;194H6[6;1H[34h[?25h[?25l[52;194H7[7;1H[34h[?25h[?25l[52;194H8[8;1H[34h[?25h[?25l[52;194H9,0-1[9;1H[34h[?25h[?25l[52;194H10,1 [10;1H[34h[?25h[?25l[52;195H1[11;1H[34h[?25h[?25l[52;195H2[12;1H[34h[?25h[?25l[52;195H3[13;1H[34h[?25h[?25l[52;195H4[14;1H[34h[?25h[?25l[52;195H5[15;1H[34h[?25h[?25l[52;195H6[16;1H[34h[?25h[?25l[52;195H7[17;1H[34h[?25h[?25l[52;195H8[18;1H[34h[?25h[?25l[52;195H9,0-1[19;1H[34h[?25h[?25l[52;194H20,1  [20;1H[34h[?25h[?25l[52;195H1[21;1H[34h[?25h[?25l[52;195H2[22;1H[34h[?25h[?25l[52;1H[K[52;1H:[34h[?25hq[?25l[34h[?25h![?25l[34h[?25h[?25l[52;1H[K[52;1H[?1l>[34h[?25h[?1049l(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ vi cv_grid_all_ml.py[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[36Pvi[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 00:40:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
Traceback (most recent call last):
  File "cv_grid_all_ml.py", line 271, in <module>
    NN_NCV.fit(x_train, y_train.ravel(), name_list=name_list, phenfile=phenfile, set_size=set_size, model_name='NN')
  File "/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv/nested_cv.py", line 307, in fit
    X_train_inner, X_test_inner, y_train_inner, y_test_inner = bash_script(train_index_inner, test_index_inner, inner_train_names, inner_test_names, outer_count, inner_count, phenfile, set_size, outer=False)
  File "/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv/nested_cv.py", line 49, in bash_script
    subprocess.run(["/external_storage/ciaran/machine_learning2/bash_script.sh", str(outer_count), str(inner_count), foo, phenfile, set_size]) 
  File "/usr/lib/python3.5/subprocess.py", line 693, in run
    with Popen(*popenargs, **kwargs) as process:
  File "/usr/lib/python3.5/subprocess.py", line 947, in __init__
    restore_signals, start_new_session)
  File "/usr/lib/python3.5/subprocess.py", line 1490, in _execute_child
    restore_signals, start_new_session, preexec_fn)
TypeError: Can't convert 'int' object to str implicitly
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?1049h[?1h=[1;52r[34l[34h[?25h[23m[24m[0m[H[J[?25l[52;1H"cv_grid_all_ml.py" 318L, 19483C[1;1H[34m#Warning : best model selected by NMAE and R2 might not be the same
#performs linear regression, linear regression, neural network, svm and random forest, LASSO, RIDGE, CNN
#source ~/venv/bin/activate #in python 3.5.2
#print a log to a .txt file!
#model = pickle.load(open('FILEPATH', 'rb')) 
#dependencies = {'coeff_determination':coeff_determination}
#model = tf.keras.models.load_model('FILEPATH', custom_objects=dependencies)
#

#import tensorflow
#import numpy as np; import scipy #need to do this before path insert
#import sys
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/')
#import dill as pickle
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv')
#from nested_cv import NestedCV
#with open('NCV_NN.pkl', 'rb') as f:
#     red = pickle.load(f)[0m

[36mprint[0m([31m"Please remember to set the right set size in the nested_cv code"[0m)
[35mimport[0m sys
sys.path.insert([31m1[0m, [31m'/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv'[0m)
num = sys.argv[[31m1[0m] [34m#script number for saving out[0m
phenfile = [36mstr[0m(sys.argv[[31m2[0m]) [34m#txt file with phenotypes[0m
data = [36mstr[0m(sys.argv[[31m3[0m]) [34m#needs to be same size as set_size[0m
snps = [36mstr[0m(sys.argv[[31m4[0m]) [34m#top or shuf[0m
phenotype = [36mstr[0m(sys.argv[[31m5[0m]) [34m#make a directory for the results[0m
set_size = [36mint[0m(sys.argv[[31m6[0m]) [34m#how many SNPs[0m
[35mfrom[0m nested_cv [35mimport[0m NestedCV
[35mimport[0m statistics
[35mimport[0m numpy [33mas[0m np
[35mimport[0m sklearn
[35mimport[0m seaborn [33mas[0m sns
[35mfrom[0m sklearn [35mimport[0m preprocessing
[35mfrom[0m sklearn.pipeline [35mimport[0m make_pipeline, Pipeline
[35mfrom[0m sklearn.preprocessing [35mimport[0m StandardScaler
[35mimport[0m datetime
[35mimport[0m time
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m matplotlib.pyplot [33mas[0m plt
[35mfrom[0m matplotlib [35mimport[0m style
[35mfrom[0m sklearn.svm [35mimport[0m LinearSVR
[35mfrom[0m sklearn.svm [35mimport[0m SVR
[35mfrom[0m sklearn.model_selection [35mimport[0m train_test_split
[35mfrom[0m sklearn.model_selection [35mimport[0m RandomizedSearchCV
[35mfrom[0m sklearn.linear_model [35mimport[0m LinearRegression, Lasso, Ridge
[34m#import pickle #use dill instead below[0m
[35mfrom[0m sklearn.ensemble [35mimport[0m RandomForestRegressor [34m#based in part on https://towardsdatascience.com/random-forest-in-python-24d0893d51c0[0m
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m os
[35mimport[0m pandas [33mas[0m pd [34m# data processing, CSV file I/O (e.g. pd.read_csv)[0m[52;194H1,1[11CTop[1;1H[34h[?25h[?25l[52;194H2[2;1H[34h[?25h[?25l[52;1H[K[52;1H:[34h[?25hq[?25l[34h[?25h![?25l[34h[?25h[?25l[52;1H[K[52;1H[?1l>[34h[?25h[?1049l(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ /external_storage/ciaran/machine_learning2/bash_script.shv/external_storage/ciaran/machine_learning2/bash_script.shi/external_storage/ciaran/machine_learning2/bash_script.sh /external_storage/ciaran/machine_learning2/bash_script.sh
[?1049h[?1h=[1;52r[34l[34h[?25h[23m[24m[0m[H[J[?25l[52;1H"/external_storage/ciaran/machine_learning2/bash_script.sh" 96L, 7070C[1;1H[34m#!/bin/bash

#phenofile='/home/ciaran/arabadopsis/phenotypes/values_FT16.8424.80.del'
#phenofile='/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del'
#pheno='FT10'
#phenotype file is first argument e.g /home/ciaran/arabadopsis/phenotypes/values_FT16.8424.80.del
#cleanup
#rm test_raw_plink* ; rm train_raw_plink*[0m
[33mecho[0m[31m [0m[33m"[0m[35m$1[0m[33m"
echo[0m[31m [0m[33m"[0m[35m$2[0m[33m"
echo[0m[31m [0m[33m"[0m[35m$3[0m[33m"[0m
[34m#conduct GWAS
#plink2 --glm --mac 20 --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids --out nested_cv_gwas_out_"$1"_in_"$2"_"$3" --keep name_vector_train.txt --pheno $phenofile
#echo "red"
#cat header.txt <(sort -g -k 12,12 nested_cv_gwas_out_"$1"_in_"$2"_"$3"."$pheno".glm.linear | awk '{if ($12 != "NA") print}' | tail -n +2) > gwas_results_"$1"_in_"$2"_"$3".gsorted #formatting[0m
[33mecho[0m[31m [0m[33m"[0m[31mblue[0m[33m"[0m
[34m#clump
#plink1.9 --prune --pheno $phenofile --bfile /home/alexg/hopefully_final/completed_big_matrix_binary_new_snps_ids --clump-kb 250 --clump-p1 1 --clump-p2 1 --clump-r2 0.1 --clump gwas_results_"$1"_in_"$2"_"$3".gss[19;1Horted --out gwas_results_clumped_"$1"_in_"$2"_"$3"
#echo "yellow"
#head -n 10000 gwas_results_clumped_"$1"_in_"$2"_"$3".clumped | awk '{print $3}'  > top10ksnps_"$1"_in_"$2"_"$3".txt
#extract top snps
#plink1.9 --prune --pheno $phenofile --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids --keep name_vector_train.txt --extract top10ksnps_"$1"_in_"$2"_"$3".txt --recode A --out train_raw_plink_"$1"_inn[24;1H_"$2"_"$3"

#plink1.9 --prune --pheno $phenofile --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids --keep name_vector_test.txt --extract top10ksnps_"$1"_in_"$2"_"$3".txt --recode A --out test_raw_plink_"$1"_in_""[27;1H$2"_"$3"[0m
[33mecho[0m[31m [0m[33m"[0m[31mpurple[0m[33m"[0m


[34m#rm name_vector_train.txt ; rm name_vector_test.txt[0m

[33mif [[0m [33m"[0m[35m$1[0m[33m"[0m [33m==[0m [33m"[0m[31mshuf[0m[33m"[0m [33m]
then[0m

[34m#choose shuf set[0m[37;9Hshuf /external_storage/ciaran/greml/indep_snps_full_dataset_new_snp_ids.prune.in [33m|[0m head [33m-n[0m [35m$5[0m [33m>[0m shuf_[33m"[0m[35m$5[0m[33m"[0m_snps_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[0m.txt[39;9Hplink[31m1.9[0m [35m--pheno[0m [35m$phenofile[0m [35m--prune[0m [35m--bfile[0m /home/ciaran/completed_big_matrix_binary_new_snps_ids   [35m--keep[0m name_vector_train.txt [35m--extract[0m shuf_[33m"[0m[35m$5[0m[33m"[0m_snps_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[0m.txt [35m--recode[0m A [35m--out[0m train_raw__[40;1Hplink_shuf_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[0m[42;9Hplink[31m1.9[0m  [35m--pheno[0m [35m$phenofile[0m [35m--prune[0m [35m--bfile[0m /home/ciaran/completed_big_matrix_binary_new_snps_ids   [35m--keep[0m name_vector_test.txt [35m--extract[0m shuf_[33m"[0m[35m$5[0m[33m"[0m_snps_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[0m.txt [35m--recode[0m A [35m--out[0m test_raw_pp[43;1Hlink_shuf_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[45;9Hmv[0m name_vector_train.txt name_vector_train_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[0m.txt [33m;[0m [33mmv[0m name_vector_test.txt name_vector_test_[33m"[0m[35m$1[0m[33m"[0m_in_[33m"[0m[35m$2[0m[33m"[0m_[33m"[0m[35m$3[0m[33m"[0m.txt

[33mfi


if [[0m [33m"[0m[35m$1[0m[33m"[0m [33m==[0m [33m"[0m[31mtop[0m[33m"[0m [33m]
then[0m[52;194H1,1[11CTop[1;1H[34h[?25h[?25l[52;194H2,0-1[2;1H[34h[?25h[?25l[52;194H3,1  [3;1H[34h[?25h[?25l[52;194H4[4;1H[34h[?25h[?25l[52;194H5[5;1H[34h[?25h[?25l[52;194H6[6;1H[34h[?25h[?25l[52;194H7[7;1H[34h[?25h[?25l[52;194H8[8;1H[34h[?25h[?25l[52;194H9[9;1H[34h[?25h[?25l[52;194H10,1[10;1H[34h[?25h[?25l[52;195H1[11;1H[34h[?25h[?25l[52;195H2[12;1H[34h[?25h[?25l[52;195H3[13;1H[34h[?25h[?25l[52;195H4[14;1H[34h[?25h[?25l[52;195H5[15;1H[34h[?25h[?25l[52;195H6[16;1H[34h[?25h[?25l[52;195H7[17;1H[34h[?25h[?25l[52;195H8[18;1H[34h[?25h[?25l[52;195H9[20;1H[34h[?25h[?25l[52;194H20[21;1H[34h[?25h[?25l[52;195H1[22;1H[34h[?25h[?25l[52;195H2[23;1H[34h[?25h[?25l[52;195H3,0-1[25;1H[34h[?25h[?25l[52;195H4,1  [26;1H[34h[?25h[?25l[52;195H5[28;1H[34h[?25h[?25l[52;195H6,0-1[29;1H[34h[?25h[?25l[52;195H7[30;1H[34h[?25h[?25l[52;195H8,1  [31;1H[34h[?25h[?25l[52;195H9,0-1[32;1H[34h[?25h[?25l[52;194H30,1  [33;1H[34h[?25h[?25l[52;195H1[34;1H[34h[?25h[?25l[52;195H2,0-1[35;1H[34h[?25h[?25l[52;195H3,1  [36;1H[34h[?25h[?25l[52;195H4,1-8[37;8H[34h[?25h[?25l[52;195H5,0-1[38;1H[34h[?25h[?25l[52;195H6,1-8[39;8H[34h[?25h[?25l[52;195H7,0-1[41;1H[34h[?25h[?25l[52;1H[K[52;1H:[34h[?25hq[?25l[34h[?25h![?25l[34h[?25h[?25l[52;1H[K[52;1H[?1l>[34h[?25h[?1049l(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ history | grep 'cp'vi /external_storage/ciaran/machine_learning2/bash_script.shcv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 00:42:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
Traceback (most recent call last):
  File "cv_grid_all_ml.py", line 271, in <module>
    NN_NCV.fit(x_train, y_train.ravel(), name_list=name_list, phenfile=phenfile, set_size=set_size, model_name='NN')
  File "/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv/nested_cv.py", line 307, in fit
    X_train_inner, X_test_inner, y_train_inner, y_test_inner = bash_script(train_index_inner, test_index_inner, inner_train_names, inner_test_names, outer_count, inner_count, phenfile, set_size, outer=False)
  File "/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv/nested_cv.py", line 49, in bash_script
    subprocess.run(["/external_storage/ciaran/machine_learning2/bash_script.sh", str(outer_count), str(inner_count), foo, str(phenfile), str(set_size)]) 
  File "/usr/lib/python3.5/subprocess.py", line 693, in run
    with Popen(*popenargs, **kwargs) as process:
  File "/usr/lib/python3.5/subprocess.py", line 947, in __init__
    restore_signals, start_new_session)
  File "/usr/lib/python3.5/subprocess.py", line 1551, in _execute_child
    raise child_exception_type(errno_num, err_msg)
PermissionError: [Errno 13] Permission denied
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ cmhod[K[K[K[Khmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ chmod 777 /external_storage/ciaran/machine_learning2/bash_script.shpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[82Pvi /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 00:43:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
^Z
[1]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[75Pchmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[82Pvi /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[36Pvi[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Csource ~/venv/bin/activate[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Chistory | grep 'cp' | tailgit push[Kcommit -m "chnaging things"add . [Kcommit -m "chnaging things"push[Khistory | grep 'cp' | tailsource ~/venv/bin/activatepython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[36@grep 'name_list=name_list, model_name'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9Pp[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27Pvi[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C/external_storage/ciaran/machine_learning2/bash_script.shpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[75Pchmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[75Pchmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[82Pvi /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[36Pvi[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[36@grep 'name_list=name_list, model_name'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@#
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ #sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g' cv_grid_all_ml.py[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[75Pchmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[82Pvi /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ grep 'name_list=name_list, model_name' cv_grid_all_ml.py[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1@p
SVM_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='SVM')
RBG_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='RBG')
LASS_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='LASS')
RIDGE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='RIDGE')
RF_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='RF')
BASELINE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='baseline')
NN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='NN')
CNN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, model_name='CNN')
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ cv_grid_all_ml.pyvcv_grid_all_ml.pyicv_grid_all_ml.py cv_grid_all_ml.py
[?1049h[?1h=[1;52r[34l[34h[?25h[23m[24m[0m[H[J[?25l[52;1H"cv_grid_all_ml.py" 318L, 19483C[1;1H[34m#Warning : best model selected by NMAE and R2 might not be the same
#performs linear regression, linear regression, neural network, svm and random forest, LASSO, RIDGE, CNN
#source ~/venv/bin/activate #in python 3.5.2
#print a log to a .txt file!
#model = pickle.load(open('FILEPATH', 'rb')) 
#dependencies = {'coeff_determination':coeff_determination}
#model = tf.keras.models.load_model('FILEPATH', custom_objects=dependencies)
#

#import tensorflow
#import numpy as np; import scipy #need to do this before path insert
#import sys
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/')
#import dill as pickle
#sys.path.insert(1, '/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv')
#from nested_cv import NestedCV
#with open('NCV_NN.pkl', 'rb') as f:
#     red = pickle.load(f)[0m

[36mprint[0m([31m"Please remember to set the right set size in the nested_cv code"[0m)
[35mimport[0m sys
sys.path.insert([31m1[0m, [31m'/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv'[0m)
num = sys.argv[[31m1[0m] [34m#script number for saving out[0m
phenfile = [36mstr[0m(sys.argv[[31m2[0m]) [34m#txt file with phenotypes[0m
data = [36mstr[0m(sys.argv[[31m3[0m]) [34m#needs to be same size as set_size[0m
snps = [36mstr[0m(sys.argv[[31m4[0m]) [34m#top or shuf[0m
phenotype = [36mstr[0m(sys.argv[[31m5[0m]) [34m#make a directory for the results[0m
set_size = [36mint[0m(sys.argv[[31m6[0m]) [34m#how many SNPs[0m
[35mfrom[0m nested_cv [35mimport[0m NestedCV
[35mimport[0m statistics
[35mimport[0m numpy [33mas[0m np
[35mimport[0m sklearn
[35mimport[0m seaborn [33mas[0m sns
[35mfrom[0m sklearn [35mimport[0m preprocessing
[35mfrom[0m sklearn.pipeline [35mimport[0m make_pipeline, Pipeline
[35mfrom[0m sklearn.preprocessing [35mimport[0m StandardScaler
[35mimport[0m datetime
[35mimport[0m time
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m matplotlib.pyplot [33mas[0m plt
[35mfrom[0m matplotlib [35mimport[0m style
[35mfrom[0m sklearn.svm [35mimport[0m LinearSVR
[35mfrom[0m sklearn.svm [35mimport[0m SVR
[35mfrom[0m sklearn.model_selection [35mimport[0m train_test_split
[35mfrom[0m sklearn.model_selection [35mimport[0m RandomizedSearchCV
[35mfrom[0m sklearn.linear_model [35mimport[0m LinearRegression, Lasso, Ridge
[34m#import pickle #use dill instead below[0m
[35mfrom[0m sklearn.ensemble [35mimport[0m RandomForestRegressor [34m#based in part on https://towardsdatascience.com/random-forest-in-python-24d0893d51c0[0m
[35mfrom[0m statistics [35mimport[0m mean
[35mimport[0m os
[35mimport[0m pandas [33mas[0m pd [34m# data processing, CSV file I/O (e.g. pd.read_csv)[0m[52;194H1,1[11CTop[1;1H[34h[?25h[?25l[52;1H[K[52;1H:[34h[?25hq[?25l[34h[?25h![?25l[34h[?25h[?25l[52;1H[K[52;1H[?1l>[34h[?25h[?1049l(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ vi cv_grid_all_ml.py[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[77@#sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[75Pchmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[82Pvi /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76Pgrep 'name_list=name_list, model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[76@sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1@h[1@e[1@n[1@f[1@i[1@l[1@e[1@=[1@p[1@h[1@e[1@n[1@f[1@i[1@l[1@e[1@p[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@,[1@ [1@s[1@e[1@t[1@_[1@s[1@i[1@z[1@e[1@=[1@s[1@e[1@t[1@_[1@s[1@i[1@z[1@e[1@,[C[1@/[1@n[1@a[1@m[1@e[1@_[1@l[1@i[1@s[1@t[1@=[1@n[1@a[1@m[1@e[1@_[1@l[1@i[1@s[1@t[1@,[1@ [1@p[1@h[1@e[1@n[1@f[1@i[1@l[1@e[1@=[1@p[1@h[1@e[1@n[1@f[1@i[1@l[1@e[1@,[1@ [1@s[1@e[1@t[1@_[1@s[1@i[1@z[1@e[1@=[1@s[1@et/g' cv_grid_all_ml.py M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_/g' cv_grid_all_ml.pyyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ci/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cz/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C,/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C /g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cn/g' cv_grid_a[Cl_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cp/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C=/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cn/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cp/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C=/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C/g' cv[1P_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C,/g' cv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ sed -i 's/name_list=name_list, phenfile=phenfile, set_size=set_size,/name_list=name_list, phenfile=phenfile, set_size=set_size, snps=snps,/g' ccv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
SVM_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='SVM')
RBG_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='RBG')
LASS_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='LASS')
RIDGE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='RIDGE')
RF_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='RF')
BASELINE_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='baseline')
NN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='NN')
CNN_NCV.fit(x_train, y_train.ravel(), [01;31m[Kname_list=name_list, p[m[Khenfile=phenfile, set_size=set_size, snps=snps, model_name='CNN')
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ grep 'name_list=name_list, p' cv_grid_all_ml.pysed -i 's/name_list=name_list, phenfile=phenfile, set_size=set_size,/name_list=name_list, phenfile=phenfile, set_size=set_size, snps=snps,/g' ccv_grid_all_ml.pyM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27@grep 'name_list=name_list, p'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[9@model_name[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[77@#sed -i 's/name_list=name_list, model_name/name_list=name_list, phenfile=phenfile, set_size=set_size, model_name/g[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[75Pchmod 777 /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[82Pvi /external_storage/ciaran/machine_learning2/bash_script.sh
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccv_grid_all_ml.py[Kpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cvi cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 00:57:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
^Z
[2]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgrep 'name_list=name_list, p' cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 00:59:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno
  --prune
  --recode A

Error: Missing --pheno parameter.
For more information, try 'plink --help [flag name]' or 'plink --help | more'.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno
  --prune
  --recode A

Error: Missing --pheno parameter.
For more information, try 'plink --help [flag name]' or 'plink --help | more'.
^Z
[3]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgrep 'name_list=name_list, p' cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:21:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno
  --prune
  --recode A

Error: Missing --pheno parameter.
For more information, try 'plink --help [flag name]' or 'plink --help | more'.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno
  --prune
  --recode A

Error: Missing --pheno parameter.
For more information, try 'plink --help [flag name]' or 'plink --help | more'.
^Z
[4]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:30:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
Pheno is FT10
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 573 people remaining.
--prune: 573 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 573 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 573 people pass filters and QC.
Phenotype data is quantitative.
--recode A to train_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 192 people remaining.
--prune: 192 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 192 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 192 people pass filters and QC.
Phenotype data is quantitative.
--recode A to test_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
^Z
[5]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:38:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
Pheno is FT10
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 573 people remaining.
--prune: 573 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 573 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 573 people pass filters and QC.
Phenotype data is quantitative.
--recode A to train_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 192 people remaining.
--prune: 192 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 192 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 192 people pass filters and QC.
Phenotype data is quantitative.
--recode A to test_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
^Z
[6]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:42:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
Pheno is FT10
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 573 people remaining.
--prune: 573 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 573 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 573 people pass filters and QC.
Phenotype data is quantitative.
--recode A to train_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 192 people remaining.
--prune: 192 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 192 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 192 people pass filters and QC.
Phenotype data is quantitative.
--recode A to test_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
^Z
[7]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgrep 'name_list=name_list, p' cv_grid_all_ml.py[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
/external_storage/ciaran/machine_learning2
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:47:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
Pheno is FT10
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 573 people remaining.
--prune: 573 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 573 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 573 people pass filters and QC.
Phenotype data is quantitative.
--recode A to train_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 192 people remaining.
--prune: 192 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 192 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 192 people pass filters and QC.
Phenotype data is quantitative.
--recode A to test_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
^Z
[8]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ :q!
:q!: command not found
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ :q!python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
/external_storage/ciaran/machine_learning2
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:52:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
/external_storage/ciaran/arabadopsis/FT10cv_new_10k/shuf
SETTING OFF CUSTOM BASH SCRIPT
1
1
in
blue
purple
Pheno is FT10
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to train_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_train.txt
  --out train_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 573 people remaining.
--prune: 573 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 573 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 573 people pass filters and QC.
Phenotype data is quantitative.
--recode A to train_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
PLINK v1.90b3.31 64-bit (3 Feb 2016)       https://www.cog-genomics.org/plink2
(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to test_raw_plink_shuf_1_in_1_in.log.
Options in effect:
  --bfile /home/ciaran/completed_big_matrix_binary_new_snps_ids
  --extract shuf_10000_snps_1_in_1_in.txt
  --keep name_vector_test.txt
  --out test_raw_plink_shuf_1_in_1_in
  --pheno /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
  --prune
  --recode A

1029912 MB RAM detected; reserving 514956 MB for main workspace.
10709465 variants loaded from .bim file.
2029 people (2029 males, 0 females) loaded from .fam.
1058 phenotype values present after --pheno.
--extract: 10000 variants remaining.
--keep: 192 people remaining.
--prune: 192 people remaining.
Using 1 thread (no multithreaded calculations invoked.
Before main variant filters, 192 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
10000 variants and 192 people pass filters and QC.
Phenotype data is quantitative.
--recode A to test_raw_plink_shuf_1_in_1_in.raw ... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99%done.
^Z
[9]+  Stopped                 python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw shuf FT10cv_new_10k 10000
(venv) (base) ciaran@pg3:/external_storage/ciaran/machine_learning2$ python cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C:q![K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython cv_grid_all_ml.py 20 /home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del /home/ciaran/completed_big_matrix_binary_new_snps_ids__first_10k.raw shuf FT10cv_new_10k 10000
Please remember to set the right set size in the nested_cv code
/external_storage/ciaran/machine_learning2
WARNING THIS IS AN EDITED SCRIPT - Ciaran Kelly 2021 
 Edited with permission under liscence 
 Flex version
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ciaran/venv/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
20
/home/ciaran/arabadopsis/phenotypes/values_FT10.8424.dup.del
/home/ciaran/completed_big_matrix_binary_new_snps_ids_first_10k.raw
shuf
FT10cv_new_10k
10000
2021-12-03 14:57:00
Performing Neural Network
ADBUCE
INNER COUNT NO.  1
/external_storage/ciaran/arabadopsis/FT10cv_new_10k/shuf
test_raw_plink_shuf_1_in_1_in.raw
Set size set to 10000
Traceback (most recent call last):
  File "cv_grid_all_ml.py", line 271, in <module>
    NN_NCV.fit(x_train, y_train.ravel(), name_list=name_list, phenfile=phenfile, set_size=set_size, snps=snps, model_name='NN')
  File "/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv/nested_cv.py", line 310, in fit
    X_train_inner, X_test_inner, y_train_inner, y_test_inner = bash_script(train_index_inner, test_index_inner, inner_train_names, inner_test_names, outer_count, inner_count, phenfile, set_size, snps, outer=False)
  File "/external_storage/ciaran/Library/Python/3.7/python/site-packages/nested_cv/nested_cv.py", line 56, in bash_script
    new_X_train , new_y_train = load_data('train_raw_plink_' +  str(snps) + '_' + str(o